{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c022988-cc93-4b55-a8fb-d0472e9f3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fd14e-5c34-4d1f-a809-c15f62d0f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    #load img\n",
    "    image = tf.io.read_file(path)\n",
    "    #preprocess\n",
    "    #image = tf.cond(\n",
    "     #   tf.image.is_jpeg(image),\n",
    "      #  lambda: tf.image.decode_jpeg(image, channels=3),\n",
    "       # lambda: tf.image.decode_png(image, channels=3))\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (64, 64))\n",
    "    image = (image - 127.5) / 127.5  # [-1, 1]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5acd8-f6e7-4c0d-89d0-007669290b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normalized_dataset(path):\n",
    "    image_samples_path = list()\n",
    "    class_count = 1\n",
    "    img_sample_count = 1\n",
    "    for image_name in os.listdir(path):\n",
    "        full_image_name = os.path.join(path, image_name)\n",
    "        image_samples_path.append(full_image_name)\n",
    "        img_sample_count += 1\n",
    "        \n",
    "    class_count += 1\n",
    "\n",
    "    random.shuffle(image_samples_path)\n",
    "    scene_dataset = tf.data.Dataset.from_tensor_slices(image_samples_path)\n",
    "    scene_dataset = scene_dataset.map(load_and_preprocess_image)\n",
    "    batch_size = 8\n",
    "    scene_dataset = scene_dataset.batch(batch_size)\n",
    "\n",
    "    return scene_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1fb8d-552f-49a3-bd39-f03edc9ea1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dataset = load_normalized_dataset(\"../data/Toyota/\")\n",
    "print(list(scene_dataset.as_numpy_iterator()))\n",
    "scene_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193ea34-451c-4b7b-a2b0-9159aa333750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units=8 * 8 * 256, use_bias=False, input_shape=(100,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Reshape((8, 8, 256)),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=128, kernel_size=(3,3), strides=(2,2), padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=256, kernel_size=(3,3), strides=(2,2), padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=3, kernel_size=(3,3), strides=(2,2), padding=\"same\", use_bias=False,\n",
    "                               activation=\"tanh\"),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4f925-1283-4a49-b2c4-163e6788949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = generator()\n",
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5d917-5bb9-4f67-be18-2831455499bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f0735-8abd-4c14-938f-b3c7ce97d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_optimizer():\n",
    "    return tf.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2080b1-fb3e-47de-99a1-2131625c9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = generator_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6c426-3d76-4bda-a2c2-8a7859305860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same',\n",
    "                      input_shape=[64, 64, 3]),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(rate=0.3),\n",
    "        \n",
    "        layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(rate=0.3),\n",
    "\n",
    "        layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(rate=0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=1)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c809ca4-f41a-46e3-a08f-e7e0c964df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_model = discriminator()\n",
    "dis_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e029b9-9c2e-40bf-abc7-257c3d3710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output,\n",
    "                       fake_output):\n",
    "    cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5745d-b565-498a-a124-b5d7be9cd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_optimizer():\n",
    "    return tf.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f40edd-2e97-4598-a10e-5caec0fe524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_optimizer = discriminator_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cc675-03a9-4130-b9aa-e20cf78b2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, gen_model, gen_optimizer, dis_model, dis_optimizer, gen_loss_metric, dis_loss_metric):\n",
    "    noise = tf.random.normal([8, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = gen_model(noise, training=True)\n",
    "\n",
    "        real_output = dis_model(images, training=True)\n",
    "        fake_output = dis_model(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, dis_model.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_generator, gen_model.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(gradients_of_discriminator, dis_model.trainable_variables))\n",
    "\n",
    "    gen_loss_metric(gen_loss)\n",
    "    dis_loss_metric(disc_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d9337-617a-4e4d-9eea-60b396d9bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(real_images, gen_model, dis_model):\n",
    "    random_seed = tf.random.normal([8, 100])\n",
    "    fake_images = gen_model(random_seed, training=False)\n",
    "\n",
    "    real_dis_prediction = dis_model(real_images)\n",
    "    fake_dis_prediction = dis_model(fake_images)\n",
    "\n",
    "    correct = len(real_dis_prediction[real_dis_prediction >= 0.0])\n",
    "    wrong = len(real_dis_prediction[real_dis_prediction < 0.0])\n",
    "    real_dis_acc = float(correct) / float(correct + wrong)\n",
    "\n",
    "    correct = len(fake_dis_prediction[fake_dis_prediction < 0.0])\n",
    "    wrong = len(fake_dis_prediction[fake_dis_prediction >= 0.0])\n",
    "    fake_dis_acc = float(correct) / float(correct + wrong)\n",
    "\n",
    "    combined_dis_acc = (real_dis_acc + fake_dis_acc) / 2\n",
    "\n",
    "    return real_dis_acc, fake_dis_acc, combined_dis_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab5ba2-a644-4c1c-98fe-d2caf4badcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_accuracy(gen_loss_metric, epoch, dis_loss_metric, real_dis_acc, fake_dis_acc, combined_dis_acc):\n",
    "    print('Loss')\n",
    "    print('Generator:{}'.format(gen_loss_metric.result()))\n",
    "    print('Discriminator:{}'.format(dis_loss_metric.result()))\n",
    "    print('Accuracy')\n",
    "    print('Real Discriminator:{}'.format(real_dis_acc))\n",
    "    print('Fake Discriminator:{}'.format(fake_dis_acc))\n",
    "    print('Combined Discriminator:{}'.format(combined_dis_acc))\n",
    "    gen_loss_metric.reset_states()\n",
    "    dis_loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb59616-ba73-443e-a8b8-b748a45850e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(gen_loss_values, dis_loss_values, real_disc_acc_values, fake_disc_acc_values, combined_disc_acc_values):\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    plt.plot(gen_loss_values, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Generator loss')\n",
    "    plt.savefig('../res/Toyota2/metrics/generator_loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    plt.plot(dis_loss_values, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Discriminator loss')\n",
    "    plt.savefig('../res/Toyota2/metrics/discriminator_loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    plt.plot(real_disc_acc_values, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Real discriminator accuracy')\n",
    "    plt.savefig('../res/Toyota2/metrics/real_accuracy.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    plt.plot(fake_disc_acc_values, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Fake discriminator accuracy')\n",
    "    plt.savefig('../res/Toyota2/metrics/fake_accuracy.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    plt.plot(combined_disc_acc_values, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Combined discriminator accuracy')\n",
    "    plt.savefig('../res/Toyota2/metrics/combined_accuracy.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f43d1-ca9c-4562-9c5f-147eb0f26523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch):\n",
    "    test_input = tf.random.normal([9, 100])\n",
    "    predictions = gen_model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(3, 3))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        img = np.array(predictions[i]) * 127.5 + 127.5\n",
    "        img = img.astype(np.uint8, copy=False)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.savefig('../res/Toyota2/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a43a7-95ef-459e-b6f7-9047dd28e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(real_image_dataset,  epochs, gen_model, gen_optimizer, dis_model, dis_optimizer):\n",
    "    gen_loss_values = []\n",
    "    dis_loss_values = []\n",
    "    real_disc_acc_values = []\n",
    "    fake_disc_acc_values = []\n",
    "    combined_disc_acc_values = []\n",
    "    \n",
    "    gen_loss_metric = keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "    dis_loss_metric = keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        gen_loss = dis_loss = real_acc = fake_acc = comb_acc = 0\n",
    "        for image_batch in real_image_dataset:\n",
    "            train_step(image_batch, gen_model, gen_optimizer, dis_model, dis_optimizer, gen_loss_metric, dis_loss_metric)\n",
    "            real_dis_acc, fake_dis_acc, combined_dis_acc = test_step(image_batch, gen_model, dis_model)\n",
    "            loss_and_accuracy(gen_loss_metric, epoch, dis_loss_metric, real_dis_acc, fake_dis_acc, combined_dis_acc)\n",
    "            gen_loss += gen_loss_metric.result()\n",
    "            dis_loss += dis_loss_metric.result()\n",
    "            real_acc += real_dis_acc\n",
    "            fake_acc += fake_dis_acc\n",
    "            comb_acc += combined_dis_acc\n",
    "        gen_loss_values.append(gen_loss/len(real_image_dataset))\n",
    "        dis_loss_values.append(dis_loss/len(real_image_dataset))\n",
    "        real_disc_acc_values.append(real_acc/len(real_image_dataset))\n",
    "        fake_disc_acc_values.append(fake_acc/len(real_image_dataset))\n",
    "        combined_disc_acc_values.append(comb_acc/len(real_image_dataset))\n",
    "        #generate_and_save_images(gen_model, epoch + 1)\n",
    "    plot_graph(gen_loss_values, dis_loss_values, real_disc_acc_values, fake_disc_acc_values, combined_disc_acc_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5a909-bc61-4fb3-b4c9-957a8e306ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(real_image_dataset=scene_dataset,epochs=5000,gen_model=gen_model, gen_optimizer=gen_optimizer, dis_model=dis_model,\n",
    "            dis_optimizer=dis_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a0172-f20e-41fe-a0e5-1b9f04c1eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# import glob\n",
    "# import PIL\n",
    "# def display_image(epoch_no):\n",
    "#   return PIL.Image.open('../res/Toyota2/image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065517f5-fb6c-47a0-8f90-0518d9c645bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display_image(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453e08e-1dd5-4301-b38e-90a09f2d1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anim_file = '../res/Toyota2/gan.gif'\n",
    "\n",
    "# with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "#   filenames = glob.glob('../res/Toyota2/image*.png')\n",
    "#   filenames = sorted(filenames)\n",
    "#   for filename in filenames:\n",
    "#     image = imageio.v2.imread(filename)\n",
    "#     writer.append_data(image)\n",
    "#   image = imageio.v2.imread(filename)\n",
    "#   writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fb717-3601-4f5c-9f3f-25e405095981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# im = Image.open('../res/Toyota2/gan.gif')\n",
    "# im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c57c6-49db-4f10-a98d-e5901a311a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

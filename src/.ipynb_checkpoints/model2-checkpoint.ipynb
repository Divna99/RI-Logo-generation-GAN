{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c022988-cc93-4b55-a8fb-d0472e9f3f0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\World\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "926fd14e-5c34-4d1f-a809-c15f62d0f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    #load img\n",
    "    image = tf.io.read_file(path)\n",
    "    #preprocess\n",
    "    #image = tf.cond(\n",
    "     #   tf.image.is_jpeg(image),\n",
    "      #  lambda: tf.image.decode_jpeg(image, channels=3),\n",
    "       # lambda: tf.image.decode_png(image, channels=3))\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (56, 56))\n",
    "    image = (image - 127.5) / 127.5  # [-1, 1]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e5d5acd8-f6e7-4c0d-89d0-007669290b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normalized_dataset(path):\n",
    "    image_samples_path = list()\n",
    "    class_count = 1\n",
    "    for class_dir in os.listdir(path):\n",
    "        img_sample_count = 1\n",
    "        full_class_dir = os.path.join(path, class_dir)\n",
    "        for image_name in os.listdir(full_class_dir):\n",
    "            full_image_name = os.path.join(full_class_dir, image_name)\n",
    "            image_samples_path.append(full_image_name)\n",
    "            img_sample_count += 1\n",
    "        class_count += 1\n",
    "\n",
    "    random.shuffle(image_samples_path)\n",
    "    scene_dataset = tf.data.Dataset.from_tensor_slices(image_samples_path)\n",
    "    scene_dataset = scene_dataset.map(load_and_preprocess_image)\n",
    "    batch_size = 256\n",
    "    scene_dataset = scene_dataset.batch(batch_size)\n",
    "\n",
    "    return scene_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1fb8d-552f-49a3-bd39-f03edc9ea1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dataset = load_normalized_dataset(\"../data\")\n",
    "print(list(scene_dataset.as_numpy_iterator()))\n",
    "scene_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6193ea34-451c-4b7b-a2b0-9159aa333750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units=7 * 7 * 256, use_bias=False, input_shape=(100,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "        layers.Reshape((7, 7, 256)),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=256, kernel_size=(3,3), strides=(2,2), padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(2,2), padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "\n",
    "        layers.Conv2DTranspose(filters=3, kernel_size=(3,3), strides=(2,2), padding=\"same\", use_bias=False,\n",
    "                               activation=\"tanh\"),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "94c4f925-1283-4a49-b2c4-163e6788949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 12544)             1254400   \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 12544)             50176     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_54 (LeakyReLU)  (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_36 (Conv2  (None, 7, 7, 128)         294912    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 7, 7, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_55 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_37 (Conv2  (None, 14, 14, 256)       294912    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 14, 14, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_56 (LeakyReLU)  (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_38 (Conv2  (None, 28, 28, 64)        147456    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 28, 28, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_57 (LeakyReLU)  (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_39 (Conv2  (None, 56, 56, 3)         1728      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2045376 (7.80 MB)\n",
      "Trainable params: 2019392 (7.70 MB)\n",
      "Non-trainable params: 25984 (101.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen_model = generator()\n",
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7ef5d917-5bb9-4f67-be18-2831455499bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b17f0735-8abd-4c14-938f-b3c7ce97d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_optimizer():\n",
    "    return tf.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cf2080b1-fb3e-47de-99a1-2131625c9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = generator_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "11b6c426-3d76-4bda-a2c2-8a7859305860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same',\n",
    "                      input_shape=[56, 56, 3]),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "        layers.Dropout(rate=0.3),\n",
    "\n",
    "        layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.01),\n",
    "        layers.Dropout(rate=0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=1),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1c809ca4-f41a-46e3-a08f-e7e0c964df8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 128)       3584      \n",
      "                                                                 \n",
      " leaky_re_lu_58 (LeakyReLU)  (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 14, 14, 64)        73792     \n",
      "                                                                 \n",
      " leaky_re_lu_59 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 12545     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89921 (351.25 KB)\n",
      "Trainable params: 89921 (351.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis_model = discriminator()\n",
    "dis_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f2e029b9-9c2e-40bf-abc7-257c3d3710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output,\n",
    "                       fake_output):\n",
    "    cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f9b5745d-b565-498a-a124-b5d7be9cd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_optimizer():\n",
    "    return tf.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "55f40edd-2e97-4598-a10e-5caec0fe524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_optimizer = discriminator_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2c3cc675-03a9-4130-b9aa-e20cf78b2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, gen_model, gen_optimizer, dis_model, dis_optimizer, gen_loss_metric, dis_loss_metric):\n",
    "    noise = tf.random.normal([256, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = gen_model(noise, training=True)\n",
    "\n",
    "        real_output = dis_model(images, training=True)\n",
    "        fake_output = dis_model(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, dis_model.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_generator, gen_model.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(gradients_of_discriminator, dis_model.trainable_variables))\n",
    "\n",
    "    gen_loss_metric(gen_loss)\n",
    "    dis_loss_metric(disc_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b66d9337-617a-4e4d-9eea-60b396d9bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(real_images, gen_model, dis_model):\n",
    "    random_seed = tf.random.normal([256, 100])\n",
    "    fake_images = gen_model(random_seed, training=False)\n",
    "\n",
    "    real_dis_prediction = dis_model(real_images)\n",
    "    fake_dis_prediction = dis_model(fake_images)\n",
    "\n",
    "    correct = len(real_dis_prediction[real_dis_prediction >= 0.0])\n",
    "    wrong = len(real_dis_prediction[real_dis_prediction < 0.0])\n",
    "    real_dis_acc = float(correct) / float(correct + wrong)\n",
    "\n",
    "    correct = len(fake_dis_prediction[fake_dis_prediction < 0.0])\n",
    "    wrong = len(fake_dis_prediction[fake_dis_prediction >= 0.0])\n",
    "    fake_dis_acc = float(correct) / float(correct + wrong)\n",
    "\n",
    "    combined_dis_acc = (real_dis_acc + fake_dis_acc) / 2\n",
    "\n",
    "    return real_dis_acc, fake_dis_acc, combined_dis_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "8dab5ba2-a644-4c1c-98fe-d2caf4badcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_accuracy(gen_loss_metric, epoch, dis_loss_metric, real_dis_acc, fake_dis_acc, combined_dis_acc):\n",
    "    print('Loss')\n",
    "    print('Generator:{}'.format(gen_loss_metric.result()))\n",
    "    print('Discriminator:{}'.format(dis_loss_metric.result()))\n",
    "    print('Accuracy')\n",
    "    print('Real Discriminator:{}'.format(real_dis_acc))\n",
    "    print('Fake Discriminator:{}'.format(fake_dis_acc))\n",
    "    print('Combined Discriminator:{}'.format(combined_dis_acc))\n",
    "    gen_loss_metric.reset_states()\n",
    "    dis_loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "eb1d4e09-daeb-44f8-8057-2b846b376e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_and_biases(gen_model, epoch, dis_model):\n",
    "    print('Generator Weights')\n",
    "    for gen_layer in gen_model.layers:\n",
    "        print(gen_layer.name + ':{}'.format(gen_layer.get_weights()[0]))\n",
    "        print('Discriminator')\n",
    "        for dis_layer in dis_model.layers:\n",
    "            print('Weights')\n",
    "            print(dis_layer.name + ':{}'.format(dis_layer.get_weights()[0]))\n",
    "            print('Biases')\n",
    "            print(dis_layer.name + ':{}'.format(dis_layer.get_weights()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "463f43d1-ca9c-4562-9c5f-147eb0f26523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch):\n",
    "    test_input = tf.random.normal([9, 100])\n",
    "    predictions = gen_model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(3, 3))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        img = np.array(predictions[i]) * 127.5 + 127.5\n",
    "        img = img.astype(np.uint8, copy=False)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.savefig('../res/gif2/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3a2a43a7-95ef-459e-b6f7-9047dd28e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(real_image_dataset,  epochs, gen_model, gen_optimizer, dis_model, dis_optimizer):\n",
    "    gen_loss_metric = keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "    dis_loss_metric = keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        for image_batch in real_image_dataset:\n",
    "            train_step(image_batch, gen_model, gen_optimizer, dis_model, dis_optimizer, gen_loss_metric, dis_loss_metric)\n",
    "            real_dis_acc, fake_dis_acc, combined_dis_acc = test_step(image_batch, gen_model, dis_model)\n",
    "            loss_and_accuracy(gen_loss_metric, epoch, dis_loss_metric, real_dis_acc, fake_dis_acc, combined_dis_acc)\n",
    "        generate_and_save_images(gen_model, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5a909-bc61-4fb3-b4c9-957a8e306ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(real_image_dataset=scene_dataset,epochs=1000,gen_model=gen_model, gen_optimizer=gen_optimizer, dis_model=dis_model,\n",
    "            dis_optimizer=dis_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "106a0172-f20e-41fe-a0e5-1b9f04c1eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import glob\n",
    "import PIL\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('../res/gif2/image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065517f5-fb6c-47a0-8f90-0518d9c645bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4453e08e-1dd5-4301-b38e-90a09f2d1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = '../res/gif2/gan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('../res/gif2/image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.v2.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.v2.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fb717-3601-4f5c-9f3f-25e405095981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('../res/gif2/gan.gif')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d0ae99-b5a2-496c-a844-71e43fed8a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b30a92-ee92-41be-b3f1-c85b91582b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
